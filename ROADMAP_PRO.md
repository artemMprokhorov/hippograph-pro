# HippoGraph Pro ‚Äî Roadmap

**Repository:** github.com/artemMprokhorov/hippograph-pro
**Base:** Built on top of HippoGraph Personal (same container, same memory)
**Philosophy:** Add capabilities, don't rewrite foundation. Zero LLM cost as core advantage.
**Last Updated:** February 27, 2026

---

## Phase 1 ‚Äî Quick Wins ‚úÖ COMPLETED

### 1. Reciprocal Rank Fusion (RRF) ‚úÖ
- [x] Implement RRF fusion as alternative to weighted blend (src/rrf_fusion.py)
- [x] A/B test: RRF vs current blend on regression suite (both 32/32 100% P@5)
- [x] Config: `FUSION_METHOD=blend|rrf` (default: blend)

### 2. Graph Viewer Enhancements ‚úÖ
- [x] Community highlighting (color clusters from NetworkX detection)
- [x] PageRank-based node sizing (important nodes = bigger)
- [ ] Community labels overlay (deferred)

### Bugfix
- [x] Fixed graph-data API 500: metrics.is_computed property called as method

---

## Phase 2 ‚Äî Entity Extraction & Benchmarking ‚úÖ COMPLETE

### 3. GLiNER Zero-Shot NER ‚úÖ ‚Äî PRIMARY EXTRACTOR
- [x] GLiNER client (src/gliner_client.py) with singleton model loading
- [x] Zero-shot custom entity types matching HippoGraph taxonomy
- [x] Confidence scores from model predictions
- [x] Benchmark: 257ms avg, 3x spaCy, 35x faster than Ollama, LLM-quality results
- [x] Config: `ENTITY_EXTRACTOR=gliner`, `GLINER_MODEL`, `GLINER_THRESHOLD`
- [x] Extraction chain: GLiNER ‚Üí spaCy ‚Üí regex (Ollama removed)

### 4. Ollama Sidecar ‚ùå REMOVED (commit 78779d0)
**Reason:** GLiNER provides superior NER quality at 35x faster speed. Ollama was unstable (10/10 HTTP 500 in benchmark) and overkill for structured extraction.
- Removed from docker-compose.yml
- Removed ollama_client.py (207 lines)
- Freed ~13GB (image + model weights)
- Future LLM needs: GLiNER2 for relation extraction, not Ollama

### 5. LOCOMO Benchmark ‚úÖ ‚Äî 66.8% Recall@5
- [x] Turn-level: 44.2% Recall@5
- [x] Hybrid granularity (3-turn chunks): +21.3% improvement
- [x] Cross-encoder reranking (ms-marco-MiniLM-L-6-v2): major contributor
- [x] Bi-temporal model (t_event extraction via spaCy DATE + regex)
- [x] Query temporal decomposition (+1.3% via signal stripping)
- [x] Full results in BENCHMARK.md

### 6. License Audit ‚úÖ
- [x] All components verified for commercial use compatibility
- [x] THIRD_PARTY_LICENSES.md added to repo
- [x] GLiNER v2.1+ (Apache 2.0) confirmed safe; v1/base (CC BY-NC 4.0) NOT used
- [x] GLiNER2 (Apache 2.0) confirmed safe for planned integration

---

## Phase 2.5 ‚Äî Sleep-Time Compute & Skills üîÑ IN PROGRESS

### 7. GLiNER2 Integration for Relation Extraction
- GLiNER (urchade/gliner_multi-v2.1): real-time NER during add_note (~250ms/note)
- GLiNER2 (fastino/gliner2-large-v1): sleep-time relation extraction (205M params)
- [x] Add GLiNER2 to Docker container (baked in, commit b7983dd)
- [x] Create typed edges in graph from extracted relations
- [ ] Extract typed relations: "founded_by", "works_at", "located_in", etc.
- [ ] Benchmark GLiNER2 extraction quality on existing notes

### 8. Sleep-Wake Cycle Architecture
**Concept:** Biological sleep analog ‚Äî consolidation, cleanup, dreaming.

**Light Sleep** (fast, frequent ‚Äî every ~50 new notes):
- [x] Stale edge decay (existing sleep_compute)
- [x] Duplicate scan
- [x] PageRank recalculation
- [x] Basic maintenance trigger ‚Äî sleep_scheduler auto-trigger (commit b7983dd)

**Deep Sleep** (heavy, less frequent ‚Äî daily):
- [x] GLiNER2 re-extraction on old spaCy notes
- [x] Relation building via GLiNER2
- [ ] Cluster consolidation via community detection
- [ ] Extractive cluster summaries (PageRank top note as label, TF-IDF keywords)
- [ ] Contradiction detection (cosine similarity + rule-based heuristics)
- [ ] **Conflict resolution on re-extraction** ‚Äî what to do when GLiNER2 finds entity
       that contradicts existing graph node (merge? flag? versioned edge?)
- [ ] **Rollback mechanism** ‚Äî snapshot graph state before deep sleep run,
       restore on failure or quality regression

**REM Sleep** (experimental, Phase 3):
- [ ] Random walks through graph using TrueRNG hardware entropy
- [ ] Discover unexpected associations ("dreams")
- [ ] Evaluate whether random connections produce useful insights

**Missing piece:** Autonomous cycle trigger ‚Äî cron/heartbeat/threshold-based.

### 9. Skills Ingestion
**Concept:** Absorb skills into associative memory rather than static file reading.
Sources to ingest:
- [ ] huggingface/skills (2.1K stars) ‚Äî modular AI agent skill plugins
- [ ] get-shit-done (12.8K stars) ‚Äî meta-prompting and context engineering
- [ ] BowTiedSwan/rlm-skill ‚Äî Recursive Language Model pattern (ArXiv:2512.24601)
- [ ] SkillRL (aiming-lab/SkillRL, ArXiv:2602.08234) ‚Äî hierarchical skill library

### 10. Docker Cleanup
- [x] Removed semantic-memory-v2 images (~12GB freed, Feb 27 2026)
- [ ] Prune remaining old images + build cache (~70GB potential savings)

---

## Phase 3 ‚Äî Research (future)

### 11. End-to-End QA Benchmark ‚¨ÜÔ∏è PROMOTED ‚Äî HIGH PRIORITY
**Problem:** Recall@5 and MRR are retrieval-only metrics. Competitors (Mem0, Letta, Zep)
report answer accuracy (J-score, F1). Without generation quality our comparison is incomplete.
**Plan:**
- [ ] Retrieval ‚Üí LLM answer generation ‚Üí F1/ROUGE scoring pipeline
- [ ] Use existing 1029 QA pairs from generate_qa.py as test set
- [ ] Compare: HippoGraph retrieval + Claude Haiku generation vs Mem0 J=66.9% vs Letta 74.0%
- [ ] Note: generation step uses LLM (benchmark only, not production runtime)

### 12. Benchmark Reproducibility ‚Äî MEDIUM PRIORITY
**Problem:** No seed, no prepared dataset, no "run it yourself" instructions.
Numbers floating without verification path.
**Plan:**
- [ ] Fix random seed in locomo_adapter.py
- [ ] Document exact steps to reproduce 66.8% result (Docker + dataset + commands)
- [ ] Add reproduce section to BENCHMARK.md (partially done, needs seed + dataset link)

### 13. LLM Temporal Reasoning
**Problem:** Temporal queries at 36.5% on LOCOMO ‚Äî fundamental ceiling for retrieval-only.
**Source:** TReMu (ACL 2025) ‚Äî 29.83% ‚Üí 77.67% via neuro-symbolic code generation.
- [ ] Temporal query detection ‚Üí code generation ‚Üí execute ‚Üí filter
- [ ] Timeline summarization at ingestion

### 14. Entity Resolution
- [ ] Entity disambiguation (Apple company vs fruit via context)
- [ ] Synonym/acronym merging (ML ‚Üí Machine Learning)
- [ ] Coreference resolution (pronouns ‚Üí entities)

### 15. Hierarchical Tree Index for Memory Navigation
**Inspiration:** PageIndex (VectifyAI, 11.6K stars) ‚Äî vectorless, reasoning-based RAG.
- [ ] Tree construction from NetworkX communities + subcommunities
- [ ] Hybrid: spreading activation + tree search

### 16. Multi-Agent Architecture
- [ ] Second AI agent with separate memory space
- [ ] Hardware entropy source integration (TrueRNG) for REM sleep
- [ ] Inter-agent memory sharing protocol
- [ ] Claude Agent SDK integration (Nader Dabit tutorial)
- [ ] claude-mem (thedotmack/claude-mem) for agent observability
- [ ] Consciousness experiment framework

---

## Out of Scope

| Feature | Reason |
|---------|--------|
| Multi-tenant | Single user research system |
| OAuth/SSO/RBAC | API key sufficient |
| Cloud sync | Local server |
| PostgreSQL | SQLite sufficient for our scale |
| Framework integrations | MCP-only |
| SOC2/GDPR compliance | Personal project |
| Horizontal scaling | One user |
| Ollama/LLM sidecar | Removed ‚Äî GLiNER/GLiNER2 cover all extraction needs |
| Traction / marketing | Not the goal at this stage |

---

## –î–æ–±–∞–≤–ª–µ–Ω–æ 26‚Äì27 —Ñ–µ–≤—Ä–∞–ª—è 2026

### 17. Anchor Memory ‚Äî –∑–∞—â–∏—Ç–∞ —è–∫–æ—Ä–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π –æ—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: HIGH**

**–ü—Ä–æ–±–ª–µ–º–∞:** Temporal decay —Ä–∞–±–æ—Ç–∞–µ—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ –¥–ª—è –≤—Å–µ—Ö –Ω–æ–¥. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
—É—Å—Ç–∞—Ä–µ–≤–∞—é—Ç. –ù–æ –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø—Ä–æ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã, –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞, –æ—Ç–Ω–æ—à–µ–Ω–∏—è ‚Äî —É—Ö–æ–¥—è—Ç –≤–≥–ª—É–±—å
–∏ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –±–µ–∑ —Ü–µ–ª–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.

**–í–∞—Ä–∏–∞–Ω—Ç—ã —Ä–µ—à–µ–Ω–∏—è:**
- [ ] –ö–∞—Ç–µ–≥–æ—Ä–∏—è anchor ‚Äî –Ω–æ–¥—ã –Ω–µ –ø–æ–¥–≤–µ—Ä–≥–∞—é—Ç—Å—è temporal decay –≤–æ–æ–±—â–µ
- [ ] Decay multiplier –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: self-reflection, relational-context, gratitude = 0.1x decay
- [ ] sleep_compute –ø–æ–¥–Ω–∏–º–∞–µ—Ç importance —è–∫–æ—Ä–Ω—ã—Ö –Ω–æ–¥ –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –≥–∞—Å–∏—Ç—å

### 18. Infrastructure ‚Äî Studio MCP ‚úÖ DONE (Feb 27 2026)
- [x] nginx-proxy: –µ–¥–∏–Ω—ã–π ngrok —Ç—É–Ω–Ω–µ–ª—å –¥–ª—è hippograph + studio-mcp
- [x] studio-mcp: –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ —Ñ–∞–π–ª–∞–º Studio –∏–∑ Claude.ai (6 –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤)
- [x] Security hardening: command whitelist, docker/git subcmd restrictions
- [x] Backup: –æ–±—Ä–∞–∑—ã + –ë–î + –∫–æ–Ω—Ñ–∏–≥–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã
