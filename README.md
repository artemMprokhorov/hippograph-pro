<p align="center">
  <img src="logo.svg" width="200" alt="HippoGraph Pro Logo">
</p>

# HippoGraph Pro

> âš ï¸ **Under Active Development** â€” This is a research fork, not production-ready.
> Features may break, APIs may change, benchmarks are preliminary.
> For a stable self-hosted memory system, see [HippoGraph](https://github.com/artemMprokhorov/hippograph).

---

## What Is This?

**HippoGraph Pro** is the experimental research branch of [HippoGraph](https://github.com/artemMprokhorov/hippograph) â€” a self-hosted, graph-based semantic memory system for AI assistants via MCP.

While the base project provides a stable, zero-dependency memory layer, **Pro** is where we push boundaries: better retrieval algorithms, smarter entity extraction, and research into AI memory architectures.

### How It Differs from HippoGraph (Base)

| | **HippoGraph** (Base) | **HippoGraph Pro** |
|---|---|---|
| **Purpose** | Stable personal memory | Research & experimentation |
| **Status** | Production-ready | ğŸš§ Under construction |
| **Entity extraction** | spaCy + regex | GLiNER zero-shot NER + Ollama LLM + spaCy fallback |
| **Search** | Semantic + spreading activation | + BM25 hybrid + cross-encoder reranking + RRF fusion |
| **Benchmarks** | Internal tests | LOCOMO: 44.2% Recall@5 Â· E2E QA: 38.7% F1 (zero retrieval cost) |
| **Dependencies** | Minimal (Docker only) | + Ollama sidecar (optional), GLiNER model |
| **Graph analytics** | Basic viewer | + PageRank node sizing, community coloring |
| **Temporal model** | Created/accessed timestamps | + Bi-temporal (event time extraction) |
| **Target audience** | Anyone wanting AI memory | Researchers, contributors, the curious |

---

## ğŸ”¬ Research Focus

This project explores several questions:

- **Retrieval quality**: Can spreading activation + BM25 + semantic search match LLM-powered systems at zero inference cost?
- **Entity extraction trade-offs**: GLiNER (250ms, LLM quality) vs Ollama 7B (6s, generation capable) vs spaCy (10ms, basic) â€” what's the right tool for each job?
- **Benchmark-driven development**: How does a lightweight graph memory compare to Mem0, Zep/Graphiti, and Letta on standardized benchmarks?

### Current Benchmarks

**Retrieval â€” LOCOMO (turn-level, zero LLM cost):**

```
| Category    | Recall@5 | MRR   |
|-------------|----------|-------|
| Overall     | 44.2%    | 0.304 |
| Single-hop  | 37.9%    | 0.227 |
| Multi-hop   | 52.6%    | 0.394 |
| Temporal    | 22.9%    | 0.139 |
| Open-domain | 45.5%    | 0.314 |
```

**End-to-End QA â€” HippoGraph internal dataset (1,311 pairs, Claude Haiku generation):**

```
| Category     | F1    | ROUGE-1 |
|--------------|-------|---------|
| Overall      | 38.7% | 66.8%   |
| Factual      | 40.2% | 67.6%   |
| Temporal     | 29.2% | 58.5%   |
| Entity       | 24.9% | 64.5%   |
```

> GPT-4 without memory: F1=32.1% â€” HippoGraph +6.6pp with zero retrieval LLM cost.
> âš ï¸ Mem0 (J-score 66.9%) and Letta (74.0%) use different metrics â€” not directly comparable.
> See [BENCHMARK.md](BENCHMARK.md) for full methodology.

---

## ğŸ—ï¸ Architecture

### Entity Extraction Chain

```
Input text
    â†“
GLiNER (primary) â”€â”€â”€ zero-shot NER, ~250ms, custom entity types
    â†“ fallback
spaCy NER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ basic extraction, ~10ms, fixed entity types
    â†“ fallback
Regex â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ dictionary matching only
```

### Search Pipeline

```
Query â†’ Embedding â†’ ANN Search (HNSW)
                        â†“
             Spreading Activation (3 iterations, decay=0.7)
                        â†“
             BM25 Keyword Search (Okapi BM25)
                        â†“
             Blend: Î±Ã—semantic + Î²Ã—spreading + Î³Ã—BM25
                        â†“
             Cross-Encoder Reranking (optional)
                        â†“
             Temporal Decay â†’ Top-K Results
```

### Infrastructure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  hippograph          â”‚
â”‚  (main container)    â”‚
â”‚                      â”‚
â”‚  Flask API :5001     â”‚
â”‚  Graph Viewer :5002  â”‚
â”‚  SQLite + FAISS      â”‚
â”‚  GLiNER + spaCy      â”‚
â”‚  sentence-transformersâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

> **Prerequisites:** Docker & Docker Compose, 4GB+ RAM

```bash
git clone https://github.com/artemMprokhorov/hippograph-pro.git
cd hippograph-pro
cp .env.example .env
# Edit .env: set NEURAL_API_KEY and ENTITY_EXTRACTOR=gliner

docker-compose up -d

# Verify
curl http://localhost:5001/health
```

**Graph Viewer:** `http://localhost:5002`

---

## ğŸ“‹ Pro-Only Features

Features added on top of HippoGraph base:

| Feature | Status | Description |
|---------|--------|-------------|
| GLiNER NER | âœ… Deployed | Zero-shot entity extraction, 35x faster than LLM |
| BM25 Hybrid Search | âœ… Deployed | Three-signal blend scoring (semantic + graph + keyword) |
| RRF Fusion | âœ… Deployed | Reciprocal Rank Fusion as alternative to weighted blend |
| Cross-Encoder Reranking | âœ… Deployed | ms-marco-MiniLM precision improvement |
| PageRank + Communities | âœ… Deployed | Graph analytics in viewer |
| Bi-Temporal Model | âœ… Deployed | Event time extraction for temporal queries |
| LOCOMO Benchmark | âœ… Complete | Standardized evaluation framework |
| Sleep-Time LLM Compute | ğŸ”„ In Progress | Re-extract entities, discover connections |
| Hierarchical Tree Index | ğŸ“‹ Research | Top-down navigation via community trees |
| Temporal Reasoning | ğŸ“‹ Research | LLM-powered temporal query answering |
| End-to-End QA | ğŸ“‹ Planned | Answer generation for benchmark comparison |

---

## ğŸ“Š Competitive Landscape

See [competitive_analysis.md](competitive_analysis.md) for detailed comparison with Mem0, Zep/Graphiti, Letta, and others.

**Our niche:** Self-hosted, zero-LLM-cost retrieval, graph-based associative memory. The only project combining spreading activation with hybrid BM25 search and zero-shot NER at zero API cost.

---

## ğŸ“– Documentation

- [BENCHMARK.md](BENCHMARK.md) â€” LOCOMO benchmark results and methodology
- [ROADMAP_PRO.md](ROADMAP_PRO.md) â€” Development roadmap
- [THIRD_PARTY_LICENSES.md](THIRD_PARTY_LICENSES.md) â€” Third-party dependencies and licenses
- [competitive_analysis.md](competitive_analysis.md) â€” Market positioning
- [docs/](docs/) â€” Setup guides, API reference, troubleshooting

---

## ğŸ“„ License

Dual-licensed: MIT for open-source/personal use, commercial license required for business use.
See [LICENSE](LICENSE) for details. Contact: system.uid@gmail.com

---

## ğŸ‘¥ Authors

**Artem Prokhorov** â€” Creator and primary author

Developed through human-AI collaboration with Claude (Anthropic).
Major architectural decisions, benchmarking, and research direction by Artem.

Built with ğŸ§  and ğŸŸ (the [goldfish with antlers](https://github.com/artemMprokhorov/hippograph))
